{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# AppliedML solution file reader\n\nThis notebook is used for reading solutions. Note: it will only print the first 5 error messages of each check.",
      "metadata": {
        "cell_id": "00000-a8acba35-8429-49ac-a29e-bb80ec294d13",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We start by defining the folder holding the solutions",
      "metadata": {
        "cell_id": "00001-86569691-5e9b-4661-8e82-c79836f63909",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-33e93a5b-5eb1-43ff-a744-496f480eebb1",
        "deepnote_cell_type": "code"
      },
      "source": "directory = 'solutions'",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we read all the files in the folder, which correspond to the format, and verify the prediction/variablelist pairs",
      "metadata": {
        "cell_id": "00003-b40526b6-43a8-4619-9e6b-74318f61a91b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-26a80c84-1e8d-4659-bf12-6cbb65aa80fc",
        "deepnote_cell_type": "code"
      },
      "source": "import os\n\ndef init_entry():\n    tmp = {}\n    tmp['Classification'] = {}\n    tmp['Regression'] = {}\n    tmp['Clustering'] = {}\n    return tmp\n\ndef read_filenames(directory):\n    tmp = {}\n    for filename in os.listdir(directory):\n        full_path = f'{directory}/{filename}'\n        if not os.path.isfile(full_path) or not filename.endswith('.txt'):\n            continue\n        splitted = filename.split('_')\n        \n        project_part = splitted[0]\n        student_name = splitted[1]\n        is_varlist = splitted[-1].lower() == 'variablelist.txt'\n        implementation = splitted[-2] if is_varlist else splitted[-1].split('.txt')[0]\n        \n        if student_name not in tmp:\n            tmp[student_name] = init_entry()\n        if implementation not in tmp[student_name][project_part]:\n            tmp[student_name][project_part][implementation] = {}\n        \n        if is_varlist:\n            tmp[student_name][project_part][implementation]['vars'] = full_path\n        else:\n            tmp[student_name][project_part][implementation]['preds'] = full_path\n    return tmp\n\nall_errors = 0\nerrors = 0\ndef write_error(msg, cap=5):\n    global errors\n    if errors < cap:\n        print (msg)\n    errors += 1\n\nnames = read_filenames(directory)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we can print the structure:",
      "metadata": {
        "cell_id": "00005-b9c5766d-1f7b-4ca2-8345-135dca15bd56",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00006-b1bb9430-5e96-4432-8584-4717ef2cac55",
        "deepnote_cell_type": "code"
      },
      "source": "all_errors += errors\nerrors = 0\n\nfor name, parts in names.items():\n    print (f'{name}:')\n    for part, implementations in parts.items():\n        print (f'    {part}:')\n        if len(implementations) == 0:\n            write_error(f'        {part} does not have any files')\n        else:\n            for implementation, files in implementations.items():\n                if ('vars' not in files) and ('preds' not in files):\n                    write_error(f'            {implementation} does not have a full prediction/variablelist set')\n                else:\n                    print (f'        {implementation}:')\n                    print (f'            preds: {files[\"preds\"]}')\n                    print (f'            vars:  {files[\"vars\"]}')\n\nif errors == 0:\n    print ('Files read succesfully')\nelse:\n    print (f'Reading files gave {errors} errors')",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "CarlJohnsen:\n    Classification:\n        lightgbm1:\n            preds: solutions/Classification_CarlJohnsen_lightgbm1.txt\n            vars:  solutions/Classification_CarlJohnsen_lightgbm1_VariableList.txt\n        sgd1:\n            preds: solutions/Classification_CarlJohnsen_sgd1.txt\n            vars:  solutions/Classification_CarlJohnsen_sgd1_VariableList.txt\n        tensorflow1:\n            preds: solutions/Classification_CarlJohnsen_tensorflow1.txt\n            vars:  solutions/Classification_CarlJohnsen_tensorflow1_VariableList.txt\n    Regression:\n        xgboost1:\n            preds: solutions/Regression_CarlJohnsen_xgboost1.txt\n            vars:  solutions/Regression_CarlJohnsen_xgboost1_VariableList.txt\n    Clustering:\n        scikitkmeans1:\n            preds: solutions/Clustering_CarlJohnsen_scikitkmeans1.txt\n            vars:  solutions/Clustering_CarlJohnsen_scikitkmeans1_VariableList.txt\nFiles read succesfully\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we verify the VariableList files",
      "metadata": {
        "cell_id": "00007-3f2fcc96-9ad8-4086-ba37-bc629e12f195",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00008-54df1166-92c0-4613-ab54-2f896ec0d424",
        "deepnote_cell_type": "code"
      },
      "source": "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\nmax_variables = {\n    'Classification': 15,\n    'Regression': 10,\n    'Clustering': 25,\n}\n\nall_errors += errors\nerrors = 0\nfor student_name, parts in names.items():\n    for part, implementations in parts.items():\n        for implementation, files in implementations.items():\n            file = files['vars']\n            count = 0\n            with open(file, 'r') as f:\n                for line in f:\n                    var_name = line.rstrip()\n                    if var_name not in all_variables:\n                        write_error(f'Variable {var_name} not in the given variable list {file}')\n                    else:\n                        count += 1\n            if count > max_variables[part]:\n                write_error(f'Used too many variables ({count}/{max_variables[part]}) for {part}: {file}')\n                    \nif errors == 0:\n    print ('Variables parsed without error')\nelse:\n    print (f'Variables had {errors} errors')",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Variables parsed without error\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we can verify than the solution files",
      "metadata": {
        "cell_id": "00009-6ab4cadc-a8e1-490d-b770-d88495bda5a4",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00010-3ceb34ac-d860-4a09-a6c4-3467be5ea537",
        "deepnote_cell_type": "code"
      },
      "source": "test_entries = 160651\nprediction_range = {\n    'Classification': (0.0, 1.0),\n    'Regression': (-float('inf'), float('inf')),\n    'Clustering': (-float('inf'), float('inf')),\n}\n\nall_errors += errors\nerrors = 0\nfor student_name, parts in names.items():\n    for part, implementations in parts.items():\n        for implementation, files in implementations.items():\n            file = files['preds']\n            with open(file, 'r') as f:\n                lines = [line for line in f]\n            for i in range(len(lines)):\n                if ',' in lines[i]:\n                    index, value = lines[i].lstrip().rstrip().split(',')\n                    try:\n                        if int(index) != i:\n                            write_error(f'Index at line {i+1} does not have correct index: {index}')\n                    except ValueError:\n                        write_error(f'Unable to cast the index to an integer: {index} in {file}')\n                else:\n                    value = lines[i].lstrip().rstrip()\n                value = float(value)\n                if part == 'Clustering':\n                    if value.is_integer():\n                        value = int(value)\n                    else:\n                        write_error(f'Clustering value at {i} is not an integer: {value} in {file}')\n                        continue\n                mi, ma = prediction_range[part]\n                if not (value >= mi and value <= ma):\n                    write_error(f'Value at {i} is not in the permitted range of ({mi},{ma}): {value} in {file}')\n            if len(lines) != test_entries:\n                write_error(f'Not enough predictions. Got {len(lines)}, expected {test_entries}')\n                \nif errors == 0:\n    print ('Solutions parsed without error')\nelse:\n    print (f'Solutions had {errors} errors')",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Solutions parsed without error\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Finally, we check if all of the steps completed without error:",
      "metadata": {
        "cell_id": "00011-5d3178e6-9b03-47bd-8149-4e5bb1229537",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00012-1d1f7d5b-f5c8-4c08-a9e9-dd7df63f668b",
        "deepnote_cell_type": "code"
      },
      "source": "if all_errors == 0:\n    print ('All of parts of this submission had no errors')\nelse:\n    print (f'This submission had {all_errors} errors')",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "All of parts of this submission had no errors\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=68e70cc0-4a2e-4baa-91ca-7b7df4c59022' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "deepnote_notebook_id": "9ecae470-0da5-478c-883d-9f2578607995",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}